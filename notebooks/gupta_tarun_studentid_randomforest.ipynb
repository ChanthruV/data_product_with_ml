{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas, numpy packages and dump from joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved sets from data/processed using numpy\n",
    "X_train = np.load('../data/processed/X_train.npy')\n",
    "X_val   = np.load('../data/processed/X_val.npy'  )\n",
    "y_train = np.load('../data/processed/y_train.npy')\n",
    "y_val   = np.load('../data/processed/y_val.npy'  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Training (Subset): 2032.214614112016\n",
      "MSE Validation: 10008.039590741695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sys\n",
    "\n",
    "# Assuming X_train, y_train, X_val, and y_val have been defined elsewhere\n",
    "\n",
    "# Specify the fraction of data to use (e.g., 20%)\n",
    "data_fraction = 0.2\n",
    "\n",
    "# Randomly select a subset of the data for training\n",
    "X_train_subset, _, y_train_subset, _ = train_test_split(\n",
    "    X_train, y_train, train_size=data_fraction, random_state=42\n",
    ")\n",
    "\n",
    "# Create a RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model on the subset of the data\n",
    "rf_model.fit(X_train_subset, y_train_subset)\n",
    "\n",
    "# Calculate the predicted values for the training and validation sets using the subset\n",
    "predicted_values_train_subset = rf_model.predict(X_train_subset)\n",
    "predicted_values_val = rf_model.predict(X_val)\n",
    "\n",
    "# Modify the system path to include the directory where print_mse is located\n",
    "sys.path.insert(1, '..')\n",
    "from src.models.performance import print_mse\n",
    "\n",
    "# Display the MSE score\n",
    "print_mse(y_actuals=y_train_subset, y_preds=predicted_values_train_subset, set_name='Training (Subset)')\n",
    "print_mse(y_actuals=y_val, y_preds=predicted_values_val, set_name='Validation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/rf_model.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dump from joblib and save the model\n",
    "from joblib import dump \n",
    "\n",
    "dump(rf_model,  '../models/rf_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af55d801",
   "metadata": {},
   "source": [
    "Random Forest performs well. Among current models tested, it performs better than the baseline and all iterations of XGBoost. Despite fitting this model on 20% of the data, it was still time-consuming and computationally inefficient to train. Given this, we will not explore this model further and instead dedicate resources to our other models to determine which is best at predicting in these preliminary stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the pandas and numpy packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\chant\\\\AppData\\\\Local\\\\pypoetry\\\\Cache\\\\virtualenvs\\\\data-product-with-ml-ZVsQeeWq-py3.9\\\\Scripts\\\\python.exe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# Define the root folder where your zip files are located\n",
    "root_folder = r'C:\\Users\\chant\\OneDrive\\Desktop\\itineraries_csv'\n",
    "\n",
    "# Define the destination folder where you want to extract the CSVs\n",
    "destination_folder = r'C:\\Users\\chant\\adv_mla_2023\\data_product_with_ml\\data\\raw'\n",
    "\n",
    "# Create the destination folder if it doesn't exist\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "# Iterate through the subdirectories in the root folder\n",
    "for subdir, _, files in os.walk(root_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.zip'):\n",
    "            zip_file_path = os.path.join(subdir, file)\n",
    "            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(destination_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where the CSV files are located\n",
    "directory = r'C:\\Users\\chant\\adv_mla_2023\\data_product_with_ml\\data\\raw'\n",
    "\n",
    "# Initialize an empty list to store DataFrames from individual CSV files\n",
    "dfs = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Read each CSV file into a DataFrame and append it to the list\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into one\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Now, combined_df contains all the data from the CSV files in a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chant\\adv_mla_2023\\data_product_with_ml\\notebooks\\vimalasri_chanthru-25048240-data-preparation.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chant/adv_mla_2023/data_product_with_ml/notebooks/vimalasri_chanthru-25048240-data-preparation.ipynb#Y106sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m output_csv_path \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mchant\u001b[39m\u001b[39m\\\u001b[39m\u001b[39madv_mla_2023\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdata_product_with_ml\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\\\u001b[39m\u001b[39minterim\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mcombined_data.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chant/adv_mla_2023/data_product_with_ml/notebooks/vimalasri_chanthru-25048240-data-preparation.ipynb#Y106sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Save the combined DataFrame to a CSV file\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chant/adv_mla_2023/data_product_with_ml/notebooks/vimalasri_chanthru-25048240-data-preparation.ipynb#Y106sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m combined_df\u001b[39m.\u001b[39mto_csv(output_csv_path, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chant/adv_mla_2023/data_product_with_ml/notebooks/vimalasri_chanthru-25048240-data-preparation.ipynb#Y106sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Print a message to confirm that the CSV file has been saved\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chant/adv_mla_2023/data_product_with_ml/notebooks/vimalasri_chanthru-25048240-data-preparation.ipynb#Y106sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCombined DataFrame saved to \u001b[39m\u001b[39m{\u001b[39;00moutput_csv_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify the path where to save the combined DataFrame as a CSV file\n",
    "output_csv_path = r'C:\\Users\\chant\\adv_mla_2023\\data_product_with_ml\\data\\interim\\combined_data.csv'\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Print a message to confirm that the CSV file has been saved\n",
    "print(f\"Combined DataFrame saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = r'C:\\Users\\chant\\adv_mla_2023\\data_product_with_ml\\data\\interim\\combined_data.csv'\n",
    "combined_df = pd.read_csv(output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13519999, 23)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legId</th>\n",
       "      <th>searchDate</th>\n",
       "      <th>flightDate</th>\n",
       "      <th>startingAirport</th>\n",
       "      <th>destinationAirport</th>\n",
       "      <th>travelDuration</th>\n",
       "      <th>isBasicEconomy</th>\n",
       "      <th>isRefundable</th>\n",
       "      <th>isNonStop</th>\n",
       "      <th>totalFare</th>\n",
       "      <th>totalTravelDistance</th>\n",
       "      <th>segmentsDepartureTimeEpochSeconds</th>\n",
       "      <th>segmentsDepartureTimeRaw</th>\n",
       "      <th>segmentsArrivalTimeEpochSeconds</th>\n",
       "      <th>segmentsArrivalTimeRaw</th>\n",
       "      <th>segmentsArrivalAirportCode</th>\n",
       "      <th>segmentsDepartureAirportCode</th>\n",
       "      <th>segmentsAirlineName</th>\n",
       "      <th>segmentsAirlineCode</th>\n",
       "      <th>segmentsEquipmentDescription</th>\n",
       "      <th>segmentsDurationInSeconds</th>\n",
       "      <th>segmentsDistance</th>\n",
       "      <th>segmentsCabinCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9ca0e81111c683bec1012473feefd28f</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>PT2H29M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>248.60</td>\n",
       "      <td>947.0</td>\n",
       "      <td>1650214620</td>\n",
       "      <td>2022-04-17T12:57:00.000-04:00</td>\n",
       "      <td>1650223560</td>\n",
       "      <td>2022-04-17T15:26:00.000-04:00</td>\n",
       "      <td>BOS</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Delta</td>\n",
       "      <td>DL</td>\n",
       "      <td>Airbus A321</td>\n",
       "      <td>8940</td>\n",
       "      <td>947</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98685953630e772a098941b71906592b</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>PT2H30M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>248.60</td>\n",
       "      <td>947.0</td>\n",
       "      <td>1650191400</td>\n",
       "      <td>2022-04-17T06:30:00.000-04:00</td>\n",
       "      <td>1650200400</td>\n",
       "      <td>2022-04-17T09:00:00.000-04:00</td>\n",
       "      <td>BOS</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Delta</td>\n",
       "      <td>DL</td>\n",
       "      <td>Airbus A321</td>\n",
       "      <td>9000</td>\n",
       "      <td>947</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98d90cbc32bfbb05c2fc32897c7c1087</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>PT2H30M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>248.60</td>\n",
       "      <td>947.0</td>\n",
       "      <td>1650209700</td>\n",
       "      <td>2022-04-17T11:35:00.000-04:00</td>\n",
       "      <td>1650218700</td>\n",
       "      <td>2022-04-17T14:05:00.000-04:00</td>\n",
       "      <td>BOS</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Delta</td>\n",
       "      <td>DL</td>\n",
       "      <td>Boeing 757-200</td>\n",
       "      <td>9000</td>\n",
       "      <td>947</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>969a269d38eae583f455486fa90877b4</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>PT2H32M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>248.60</td>\n",
       "      <td>947.0</td>\n",
       "      <td>1650218340</td>\n",
       "      <td>2022-04-17T13:59:00.000-04:00</td>\n",
       "      <td>1650227460</td>\n",
       "      <td>2022-04-17T16:31:00.000-04:00</td>\n",
       "      <td>BOS</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Delta</td>\n",
       "      <td>DL</td>\n",
       "      <td>Airbus A321</td>\n",
       "      <td>9120</td>\n",
       "      <td>947</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>980370cf27c89b40d2833a1d5afc9751</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>PT2H34M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>248.60</td>\n",
       "      <td>947.0</td>\n",
       "      <td>1650203940</td>\n",
       "      <td>2022-04-17T09:59:00.000-04:00</td>\n",
       "      <td>1650213180</td>\n",
       "      <td>2022-04-17T12:33:00.000-04:00</td>\n",
       "      <td>BOS</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Delta</td>\n",
       "      <td>DL</td>\n",
       "      <td>Airbus A321</td>\n",
       "      <td>9240</td>\n",
       "      <td>947</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>b8632c8d6306eefa042de33dd303fc21</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>PT2H30M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>168.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1650247020</td>\n",
       "      <td>2022-04-17T21:57:00.000-04:00</td>\n",
       "      <td>1650256020</td>\n",
       "      <td>2022-04-17T23:27:00.000-05:00</td>\n",
       "      <td>DFW</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Spirit Airlines</td>\n",
       "      <td>NK</td>\n",
       "      <td>AIRBUS INDUSTRIE A321 SHARKLETS</td>\n",
       "      <td>9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>a5e3ac25a2a23b16e9a7c82eb3dbe5c6</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>PT2H13M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>202.60</td>\n",
       "      <td>725.0</td>\n",
       "      <td>1650198600</td>\n",
       "      <td>2022-04-17T08:30:00.000-04:00</td>\n",
       "      <td>1650206580</td>\n",
       "      <td>2022-04-17T09:43:00.000-05:00</td>\n",
       "      <td>DAL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Delta</td>\n",
       "      <td>DL</td>\n",
       "      <td>Boeing 717</td>\n",
       "      <td>7980</td>\n",
       "      <td>725</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>46cab91070ddf01f23ad6d59600c2bff</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>PT2H15M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>202.60</td>\n",
       "      <td>725.0</td>\n",
       "      <td>1650227940</td>\n",
       "      <td>2022-04-17T16:39:00.000-04:00</td>\n",
       "      <td>1650236040</td>\n",
       "      <td>2022-04-17T17:54:00.000-05:00</td>\n",
       "      <td>DAL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Delta</td>\n",
       "      <td>DL</td>\n",
       "      <td>Boeing 717</td>\n",
       "      <td>8100</td>\n",
       "      <td>725</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>b8227b6368a7bc1c8d83591695af18cb</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>PT2H16M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>202.60</td>\n",
       "      <td>725.0</td>\n",
       "      <td>1650221820</td>\n",
       "      <td>2022-04-17T14:57:00.000-04:00</td>\n",
       "      <td>1650229980</td>\n",
       "      <td>2022-04-17T16:13:00.000-05:00</td>\n",
       "      <td>DAL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Delta</td>\n",
       "      <td>DL</td>\n",
       "      <td>Boeing 717</td>\n",
       "      <td>8160</td>\n",
       "      <td>725</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2bcf2f66e9c0d933d452ab9941adf829</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>PT2H16M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>202.60</td>\n",
       "      <td>725.0</td>\n",
       "      <td>1650206580</td>\n",
       "      <td>2022-04-17T10:43:00.000-04:00</td>\n",
       "      <td>1650214740</td>\n",
       "      <td>2022-04-17T11:59:00.000-05:00</td>\n",
       "      <td>DAL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Delta</td>\n",
       "      <td>DL</td>\n",
       "      <td>Boeing 717</td>\n",
       "      <td>8160</td>\n",
       "      <td>725</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               legId  searchDate  flightDate startingAirport   \n",
       "0   9ca0e81111c683bec1012473feefd28f  2022-04-16  2022-04-17             ATL  \\\n",
       "1   98685953630e772a098941b71906592b  2022-04-16  2022-04-17             ATL   \n",
       "2   98d90cbc32bfbb05c2fc32897c7c1087  2022-04-16  2022-04-17             ATL   \n",
       "3   969a269d38eae583f455486fa90877b4  2022-04-16  2022-04-17             ATL   \n",
       "4   980370cf27c89b40d2833a1d5afc9751  2022-04-16  2022-04-17             ATL   \n",
       "..                               ...         ...         ...             ...   \n",
       "95  b8632c8d6306eefa042de33dd303fc21  2022-04-16  2022-04-17             ATL   \n",
       "96  a5e3ac25a2a23b16e9a7c82eb3dbe5c6  2022-04-16  2022-04-17             ATL   \n",
       "97  46cab91070ddf01f23ad6d59600c2bff  2022-04-16  2022-04-17             ATL   \n",
       "98  b8227b6368a7bc1c8d83591695af18cb  2022-04-16  2022-04-17             ATL   \n",
       "99  2bcf2f66e9c0d933d452ab9941adf829  2022-04-16  2022-04-17             ATL   \n",
       "\n",
       "   destinationAirport travelDuration  isBasicEconomy  isRefundable  isNonStop   \n",
       "0                 BOS        PT2H29M           False         False       True  \\\n",
       "1                 BOS        PT2H30M           False         False       True   \n",
       "2                 BOS        PT2H30M           False         False       True   \n",
       "3                 BOS        PT2H32M           False         False       True   \n",
       "4                 BOS        PT2H34M           False         False       True   \n",
       "..                ...            ...             ...           ...        ...   \n",
       "95                DFW        PT2H30M           False         False       True   \n",
       "96                DFW        PT2H13M           False         False       True   \n",
       "97                DFW        PT2H15M           False         False       True   \n",
       "98                DFW        PT2H16M           False         False       True   \n",
       "99                DFW        PT2H16M           False         False       True   \n",
       "\n",
       "    totalFare  totalTravelDistance segmentsDepartureTimeEpochSeconds   \n",
       "0      248.60                947.0                        1650214620  \\\n",
       "1      248.60                947.0                        1650191400   \n",
       "2      248.60                947.0                        1650209700   \n",
       "3      248.60                947.0                        1650218340   \n",
       "4      248.60                947.0                        1650203940   \n",
       "..        ...                  ...                               ...   \n",
       "95     168.59                  NaN                        1650247020   \n",
       "96     202.60                725.0                        1650198600   \n",
       "97     202.60                725.0                        1650227940   \n",
       "98     202.60                725.0                        1650221820   \n",
       "99     202.60                725.0                        1650206580   \n",
       "\n",
       "         segmentsDepartureTimeRaw segmentsArrivalTimeEpochSeconds   \n",
       "0   2022-04-17T12:57:00.000-04:00                      1650223560  \\\n",
       "1   2022-04-17T06:30:00.000-04:00                      1650200400   \n",
       "2   2022-04-17T11:35:00.000-04:00                      1650218700   \n",
       "3   2022-04-17T13:59:00.000-04:00                      1650227460   \n",
       "4   2022-04-17T09:59:00.000-04:00                      1650213180   \n",
       "..                            ...                             ...   \n",
       "95  2022-04-17T21:57:00.000-04:00                      1650256020   \n",
       "96  2022-04-17T08:30:00.000-04:00                      1650206580   \n",
       "97  2022-04-17T16:39:00.000-04:00                      1650236040   \n",
       "98  2022-04-17T14:57:00.000-04:00                      1650229980   \n",
       "99  2022-04-17T10:43:00.000-04:00                      1650214740   \n",
       "\n",
       "           segmentsArrivalTimeRaw segmentsArrivalAirportCode   \n",
       "0   2022-04-17T15:26:00.000-04:00                        BOS  \\\n",
       "1   2022-04-17T09:00:00.000-04:00                        BOS   \n",
       "2   2022-04-17T14:05:00.000-04:00                        BOS   \n",
       "3   2022-04-17T16:31:00.000-04:00                        BOS   \n",
       "4   2022-04-17T12:33:00.000-04:00                        BOS   \n",
       "..                            ...                        ...   \n",
       "95  2022-04-17T23:27:00.000-05:00                        DFW   \n",
       "96  2022-04-17T09:43:00.000-05:00                        DAL   \n",
       "97  2022-04-17T17:54:00.000-05:00                        DAL   \n",
       "98  2022-04-17T16:13:00.000-05:00                        DAL   \n",
       "99  2022-04-17T11:59:00.000-05:00                        DAL   \n",
       "\n",
       "   segmentsDepartureAirportCode segmentsAirlineName segmentsAirlineCode   \n",
       "0                           ATL               Delta                  DL  \\\n",
       "1                           ATL               Delta                  DL   \n",
       "2                           ATL               Delta                  DL   \n",
       "3                           ATL               Delta                  DL   \n",
       "4                           ATL               Delta                  DL   \n",
       "..                          ...                 ...                 ...   \n",
       "95                          ATL     Spirit Airlines                  NK   \n",
       "96                          ATL               Delta                  DL   \n",
       "97                          ATL               Delta                  DL   \n",
       "98                          ATL               Delta                  DL   \n",
       "99                          ATL               Delta                  DL   \n",
       "\n",
       "       segmentsEquipmentDescription segmentsDurationInSeconds   \n",
       "0                       Airbus A321                      8940  \\\n",
       "1                       Airbus A321                      9000   \n",
       "2                    Boeing 757-200                      9000   \n",
       "3                       Airbus A321                      9120   \n",
       "4                       Airbus A321                      9240   \n",
       "..                              ...                       ...   \n",
       "95  AIRBUS INDUSTRIE A321 SHARKLETS                      9000   \n",
       "96                       Boeing 717                      7980   \n",
       "97                       Boeing 717                      8100   \n",
       "98                       Boeing 717                      8160   \n",
       "99                       Boeing 717                      8160   \n",
       "\n",
       "   segmentsDistance segmentsCabinCode  \n",
       "0               947             coach  \n",
       "1               947             coach  \n",
       "2               947             coach  \n",
       "3               947             coach  \n",
       "4               947             coach  \n",
       "..              ...               ...  \n",
       "95              NaN             coach  \n",
       "96              725             coach  \n",
       "97              725             coach  \n",
       "98              725             coach  \n",
       "99              725             coach  \n",
       "\n",
       "[100 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows of data and all the columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "combined_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13519999 entries, 0 to 13519998\n",
      "Data columns (total 23 columns):\n",
      " #   Column                             Dtype  \n",
      "---  ------                             -----  \n",
      " 0   legId                              object \n",
      " 1   searchDate                         object \n",
      " 2   flightDate                         object \n",
      " 3   startingAirport                    object \n",
      " 4   destinationAirport                 object \n",
      " 5   travelDuration                     object \n",
      " 6   isBasicEconomy                     bool   \n",
      " 7   isRefundable                       bool   \n",
      " 8   isNonStop                          bool   \n",
      " 9   totalFare                          float64\n",
      " 10  totalTravelDistance                float64\n",
      " 11  segmentsDepartureTimeEpochSeconds  object \n",
      " 12  segmentsDepartureTimeRaw           object \n",
      " 13  segmentsArrivalTimeEpochSeconds    object \n",
      " 14  segmentsArrivalTimeRaw             object \n",
      " 15  segmentsArrivalAirportCode         object \n",
      " 16  segmentsDepartureAirportCode       object \n",
      " 17  segmentsAirlineName                object \n",
      " 18  segmentsAirlineCode                object \n",
      " 19  segmentsEquipmentDescription       object \n",
      " 20  segmentsDurationInSeconds          object \n",
      " 21  segmentsDistance                   object \n",
      " 22  segmentsCabinCode                  object \n",
      "dtypes: bool(3), float64(2), object(18)\n",
      "memory usage: 2.1+ GB\n"
     ]
    }
   ],
   "source": [
    "# Display the summary of columns\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key points of investigation: \n",
    "\n",
    "- dtype: object\n",
    "- Investigate missing values, potential negative values and duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalFare</th>\n",
       "      <th>totalTravelDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.352000e+07</td>\n",
       "      <td>1.256038e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.737535e+02</td>\n",
       "      <td>1.569619e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.075496e+02</td>\n",
       "      <td>8.414888e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.397000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.235800e+02</td>\n",
       "      <td>8.620000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.446000e+02</td>\n",
       "      <td>1.392000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.876000e+02</td>\n",
       "      <td>2.376000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.260610e+03</td>\n",
       "      <td>4.430000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          totalFare  totalTravelDistance\n",
       "count  1.352000e+07         1.256038e+07\n",
       "mean   3.737535e+02         1.569619e+03\n",
       "std    2.075496e+02         8.414888e+02\n",
       "min    2.397000e+01         9.700000e+01\n",
       "25%    2.235800e+02         8.620000e+02\n",
       "50%    3.446000e+02         1.392000e+03\n",
       "75%    4.876000e+02         2.376000e+03\n",
       "max    8.260610e+03         4.430000e+03"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the descriptive statistics\n",
    "combined_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Observations: no negative values for totalFare (our target) and totalTravelDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['legId',\n",
       " 'searchDate',\n",
       " 'flightDate',\n",
       " 'startingAirport',\n",
       " 'destinationAirport',\n",
       " 'travelDuration',\n",
       " 'isBasicEconomy',\n",
       " 'isRefundable',\n",
       " 'isNonStop',\n",
       " 'totalFare',\n",
       " 'totalTravelDistance',\n",
       " 'segmentsDepartureTimeEpochSeconds',\n",
       " 'segmentsDepartureTimeRaw',\n",
       " 'segmentsArrivalTimeEpochSeconds',\n",
       " 'segmentsArrivalTimeRaw',\n",
       " 'segmentsArrivalAirportCode',\n",
       " 'segmentsDepartureAirportCode',\n",
       " 'segmentsAirlineName',\n",
       " 'segmentsAirlineCode',\n",
       " 'segmentsEquipmentDescription',\n",
       " 'segmentsDurationInSeconds',\n",
       " 'segmentsDistance',\n",
       " 'segmentsCabinCode']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List of columns before cleaning \n",
    "\n",
    "columns_before = combined_df.columns.tolist()\n",
    "\n",
    "columns_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of data and save it into a variable data_cleaned\n",
    "data_cleaned=combined_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the column 'sales_revenue' and save it into variable called target\n",
    "target=data_cleaned.pop('totalFare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "legId                                     0\n",
       "searchDate                                0\n",
       "flightDate                                0\n",
       "startingAirport                           0\n",
       "destinationAirport                        0\n",
       "travelDuration                            0\n",
       "isBasicEconomy                            0\n",
       "isRefundable                              0\n",
       "isNonStop                                 0\n",
       "totalTravelDistance                  959619\n",
       "segmentsDepartureTimeEpochSeconds         0\n",
       "segmentsDepartureTimeRaw                  0\n",
       "segmentsArrivalTimeEpochSeconds           0\n",
       "segmentsArrivalTimeRaw                    0\n",
       "segmentsArrivalAirportCode                0\n",
       "segmentsDepartureAirportCode              0\n",
       "segmentsAirlineName                       0\n",
       "segmentsAirlineCode                       0\n",
       "segmentsEquipmentDescription         262676\n",
       "segmentsDurationInSeconds                 0\n",
       "segmentsDistance                     126985\n",
       "segmentsCabinCode                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm there are any missing values  \n",
    "data_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values for totalTravelDistance, segmentsDistance and segmentsEquipmentDescription. Due to the nature of these fields, will impute the first two with their mean and the last with 'None' if there is no description available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'segmentsDistance' column to numeric\n",
    "data_cleaned['segmentsDistance'] = pd.to_numeric(data_cleaned['segmentsDistance'], errors='coerce')\n",
    "\n",
    "# Replace missing values in 'segmentsDistance' with the mean of the column\n",
    "data_cleaned['segmentsDistance'].fillna(data_cleaned['segmentsDistance'].mean(), inplace=True)\n",
    "\n",
    "# Replace missing values in 'totalTravelDistance' with the mean of the column\n",
    "data_cleaned['totalTravelDistance'].fillna(data_cleaned['totalTravelDistance'].mean(), inplace=True)\n",
    "\n",
    "# Replace missing values in 'segmentsEquipmentDescription' with 'None'\n",
    "data_cleaned['segmentsEquipmentDescription'].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "legId                                0\n",
       "searchDate                           0\n",
       "flightDate                           0\n",
       "startingAirport                      0\n",
       "destinationAirport                   0\n",
       "travelDuration                       0\n",
       "isBasicEconomy                       0\n",
       "isRefundable                         0\n",
       "isNonStop                            0\n",
       "totalTravelDistance                  0\n",
       "segmentsDepartureTimeEpochSeconds    0\n",
       "segmentsDepartureTimeRaw             0\n",
       "segmentsArrivalTimeEpochSeconds      0\n",
       "segmentsArrivalTimeRaw               0\n",
       "segmentsArrivalAirportCode           0\n",
       "segmentsDepartureAirportCode         0\n",
       "segmentsAirlineName                  0\n",
       "segmentsAirlineCode                  0\n",
       "segmentsEquipmentDescription         0\n",
       "segmentsDurationInSeconds            0\n",
       "segmentsDistance                     0\n",
       "segmentsCabinCode                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm there are no missing values remaining \n",
    "\n",
    "data_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for duplicate rows and remove them\n",
    "duplicate_rows = data_cleaned.duplicated()\n",
    "if duplicate_rows.any():\n",
    "    print(f\"Number of duplicate rows: {sum(duplicate_rows)}\")\n",
    "    data_cleaned = data_cleaned[~duplicate_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique values for 'legId': 1721518\n",
      "Count of unique values for 'searchDate': 32\n",
      "Count of unique values for 'flightDate': 92\n",
      "Count of unique values for 'startingAirport': 16\n",
      "Count of unique values for 'destinationAirport': 16\n",
      "Count of unique values for 'travelDuration': 1836\n",
      "Count of unique values for 'isBasicEconomy': 2\n",
      "Count of unique values for 'isRefundable': 2\n",
      "Count of unique values for 'isNonStop': 2\n",
      "Count of unique values for 'segmentsDepartureTimeEpochSeconds': 1273965\n",
      "Count of unique values for 'segmentsDepartureTimeRaw': 1374911\n",
      "Count of unique values for 'segmentsArrivalTimeEpochSeconds': 1447133\n",
      "Count of unique values for 'segmentsArrivalTimeRaw': 1513276\n",
      "Count of unique values for 'segmentsArrivalAirportCode': 5986\n",
      "Count of unique values for 'segmentsDepartureAirportCode': 5877\n",
      "Count of unique values for 'segmentsAirlineName': 118\n",
      "Count of unique values for 'segmentsAirlineCode': 118\n",
      "Count of unique values for 'segmentsEquipmentDescription': 6883\n",
      "Count of unique values for 'segmentsDurationInSeconds': 110976\n",
      "Count of unique values for 'segmentsCabinCode': 52\n"
     ]
    }
   ],
   "source": [
    "#Handling Categorical Variables - determine number of unique categories for each of these features\n",
    "\n",
    "# Convert NumPy array to DataFrame\n",
    "data_cleaned_df = pd.DataFrame(data_cleaned, columns=data_cleaned.columns)\n",
    "\n",
    "# Select columns with dtype 'object' or 'bool'\n",
    "object_columns = data_cleaned_df.select_dtypes(include=['object', 'bool'])\n",
    "\n",
    "# Find the count of unique values for each object column\n",
    "unique_values_count_dict = {}\n",
    "for column in object_columns:\n",
    "    unique_values_count = data_cleaned_df[column].nunique()\n",
    "    unique_values_count_dict[column] = unique_values_count\n",
    "\n",
    "# Print count of unique values for each object column\n",
    "for column, count in unique_values_count_dict.items():\n",
    "    print(f\"Count of unique values for '{column}': {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'searchdate', 'flightdate', 'segmentsDepartureTimeRaw' and 'segmentsArrivalTimeRaw'can be transformed into datetime objects and then numeric.  The other time-related columns are duration based and can be converted to numeric except for 'segmentsDepartureTimeRaw' and 'segmentsArrivalTimeRaw' which are in a unique format (being separated by ||) and therefore will be handled via encoding for efficiency. \n",
    "\n",
    "The remaining variables are categorical nominal so label encoding is not ideal. A number of features have high cardinality so we will use hashing encoding for all of them for simplicity. This is especially benficial given the large size of the dataframe which makes one-hot encoding sub-optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unique id column\n",
    "#data_cleaned.drop('legId',axis=1,inplace=True)\n",
    "\n",
    "# Convert boolean columns to numeric (0 or 1)\n",
    "data_cleaned[['isBasicEconomy', 'isRefundable', 'isNonStop']] = data_cleaned[['isBasicEconomy', 'isRefundable', 'isNonStop']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#date_format_custom = \"%Y-%m-%dT%H:%M:%S.%f%z\"\n",
    "#columns_to_convert = ['segmentsDepartureTimeRaw', 'segmentsArrivalTimeRaw']\n",
    "\n",
    "# Convert timestamps to pandas Timestamp objects\n",
    "#for col in columns_to_convert:\n",
    " #   data_cleaned[col] = pd.to_datetime(data_cleaned[col], format=date_format_custom, errors='coerce')\n",
    "\n",
    "# Convert pandas Timestamp objects to Unix timestamps (integer) and then divide by 10^9\n",
    "#for col in columns_to_convert:\n",
    "#    data_cleaned[col] = (data_cleaned[col] - pd.Timestamp(\"1970-01-01 00:00:00+00:00\")) // pd.Timedelta(seconds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'duration' columns to numeric\n",
    "columns_to_convert_duration = ['travelDuration', 'segmentsDepartureTimeEpochSeconds', 'segmentsDurationInSeconds', 'segmentsArrivalTimeEpochSeconds']\n",
    "data_cleaned[columns_to_convert_duration] = data_cleaned[columns_to_convert_duration].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'searchdate' and 'flightDate' into standard datetime columns then numeric for ML \n",
    "data_cleaned[['searchDate', 'flightDate']] = data_cleaned[['searchDate', 'flightDate']].apply(lambda x: pd.to_datetime(x).astype('int64') // 10**9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Hashing Encoding \n",
    "\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Specify the columns for which you want to apply hashing encoding\n",
    "columns_to_hash = [\n",
    "    'legId',\n",
    "    'startingAirport',\n",
    "    'segmentsDepartureTimeRaw',\n",
    "    'segmentsArrivalTimeRaw',\n",
    "    'destinationAirport',\n",
    "    'isBasicEconomy',\n",
    "    'isRefundable',\n",
    "    'isNonStop',\n",
    "    'segmentsArrivalAirportCode',\n",
    "    'segmentsDepartureAirportCode',\n",
    "    'segmentsAirlineName',\n",
    "    'segmentsAirlineCode',\n",
    "    'segmentsEquipmentDescription',\n",
    "    'segmentsDistance',\n",
    "    'segmentsCabinCode'\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize the FeatureHasher\n",
    "hasher = FeatureHasher(n_features=15, input_type='string')  # Choose the number of bins (n_features)\n",
    "\n",
    "# Prepare an iterable of iterables of strings for hashing encoding\n",
    "hashed_features = []\n",
    "for row in data_cleaned[columns_to_hash].values:\n",
    "    hashed_row = [str(value) for value in row]\n",
    "    hashed_features.append(hashed_row)\n",
    "\n",
    "# Apply hashing encoding to the specified columns\n",
    "hashed_features = hasher.transform(hashed_features)\n",
    "\n",
    "# Convert hashed_features to a DataFrame\n",
    "hashed_df = pd.DataFrame(hashed_features.toarray())\n",
    "\n",
    "# Specify columns to drop\n",
    "columns_to_drop = columns_to_hash\n",
    "\n",
    "# Concatenate the hashed DataFrame with the original data and remove specified columns\n",
    "data_cleaned = pd.concat([data_cleaned.drop(columns=columns_to_drop), hashed_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['searchDate',\n",
       " 'flightDate',\n",
       " 'travelDuration',\n",
       " 'totalTravelDistance',\n",
       " 'segmentsDepartureTimeEpochSeconds',\n",
       " 'segmentsArrivalTimeEpochSeconds',\n",
       " 'segmentsDurationInSeconds',\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_after = data_cleaned.columns.tolist()\n",
    "\n",
    "columns_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns: ['legId', 'startingAirport', 'destinationAirport', 'isBasicEconomy', 'isRefundable', 'isNonStop', 'totalFare', 'segmentsDepartureTimeRaw', 'segmentsArrivalTimeRaw', 'segmentsArrivalAirportCode', 'segmentsDepartureAirportCode', 'segmentsAirlineName', 'segmentsAirlineCode', 'segmentsEquipmentDescription', 'segmentsDistance', 'segmentsCabinCode']\n"
     ]
    }
   ],
   "source": [
    "#Collate list of removed columns and save into list - if test_data becomes accesible, can be used to clean data more efficiently \n",
    "\n",
    "removed_columns = [column for column in columns_before if column not in columns_after]\n",
    "\n",
    "print(\"Removed columns:\", removed_columns)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the list using pickle\n",
    "with open('removed_columns.pkl', 'wb') as f:\n",
    "    pickle.dump(removed_columns, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13519999, 22)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>searchDate</th>\n",
       "      <th>flightDate</th>\n",
       "      <th>travelDuration</th>\n",
       "      <th>totalTravelDistance</th>\n",
       "      <th>segmentsDepartureTimeEpochSeconds</th>\n",
       "      <th>segmentsArrivalTimeEpochSeconds</th>\n",
       "      <th>segmentsDurationInSeconds</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1650067200</td>\n",
       "      <td>1650153600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>947.0</td>\n",
       "      <td>1.650215e+09</td>\n",
       "      <td>1.650224e+09</td>\n",
       "      <td>8940.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1650067200</td>\n",
       "      <td>1650153600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>947.0</td>\n",
       "      <td>1.650191e+09</td>\n",
       "      <td>1.650200e+09</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1650067200</td>\n",
       "      <td>1650153600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>947.0</td>\n",
       "      <td>1.650210e+09</td>\n",
       "      <td>1.650219e+09</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1650067200</td>\n",
       "      <td>1650153600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>947.0</td>\n",
       "      <td>1.650218e+09</td>\n",
       "      <td>1.650227e+09</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1650067200</td>\n",
       "      <td>1650153600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>947.0</td>\n",
       "      <td>1.650204e+09</td>\n",
       "      <td>1.650213e+09</td>\n",
       "      <td>9240.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   searchDate  flightDate  travelDuration  totalTravelDistance   \n",
       "0  1650067200  1650153600             NaN                947.0  \\\n",
       "1  1650067200  1650153600             NaN                947.0   \n",
       "2  1650067200  1650153600             NaN                947.0   \n",
       "3  1650067200  1650153600             NaN                947.0   \n",
       "4  1650067200  1650153600             NaN                947.0   \n",
       "\n",
       "   segmentsDepartureTimeEpochSeconds  segmentsArrivalTimeEpochSeconds   \n",
       "0                       1.650215e+09                     1.650224e+09  \\\n",
       "1                       1.650191e+09                     1.650200e+09   \n",
       "2                       1.650210e+09                     1.650219e+09   \n",
       "3                       1.650218e+09                     1.650227e+09   \n",
       "4                       1.650204e+09                     1.650213e+09   \n",
       "\n",
       "   segmentsDurationInSeconds    0    1    2    3    4    5    6    7    8   \n",
       "0                     8940.0  2.0  0.0 -2.0  2.0 -2.0  0.0  0.0 -2.0 -1.0  \\\n",
       "1                     9000.0  2.0  0.0 -2.0  2.0 -2.0  0.0  0.0 -1.0  2.0   \n",
       "2                     9000.0  1.0  1.0 -2.0  2.0 -2.0  0.0  0.0 -2.0 -1.0   \n",
       "3                     9120.0  2.0  0.0 -2.0  2.0 -3.0  0.0  0.0 -2.0  0.0   \n",
       "4                     9240.0  2.0  0.0 -2.0  2.0 -2.0  0.0 -1.0 -2.0  0.0   \n",
       "\n",
       "     9   10   11   12   13   14  \n",
       "0  0.0  0.0  0.0  1.0  1.0  0.0  \n",
       "1 -1.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Split Train and Test Sets for Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import StandardScaler from sklearn.preprocessing and instantiate the StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Import StandardScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data_cleaned.columns = data_cleaned.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chant\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\data-product-with-ml-ZVsQeeWq-py3.9\\lib\\site-packages\\sklearn\\utils\\extmath.py:1047: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\chant\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\data-product-with-ml-ZVsQeeWq-py3.9\\lib\\site-packages\\sklearn\\utils\\extmath.py:1052: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\chant\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\data-product-with-ml-ZVsQeeWq-py3.9\\lib\\site-packages\\sklearn\\utils\\extmath.py:1072: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "# Fit and apply the scaling on data_cleaned\n",
    "data_cleaned=scaler.fit_transform(data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/scaler_dropped_fe.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dump from joblib and save the scaler into the folder models and call the file scaler.joblib\n",
    "from joblib import dump\n",
    "\n",
    "dump(scaler, '../models/scaler_dropped_fe.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import function scaler_split_train_test from data.sets\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "from src.data.sets import split_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the scaler data into training (80%) and validation (20%)\n",
    "X_train, X_val, y_train, y_val=split_train_test(df=data_cleaned,target=target,test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the function save_sets from sets and save the sets into the folder data/processed\n",
    "from src.data.sets import save_sets\n",
    "save_sets(X_train, y_train, X_val, y_val, path='../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the function load_sets from sets and load the sets from data/processed\n",
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import statistics\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the mode of the target variable from the training set\n",
    "y_mode=mode(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a numpy array called y_base of dimensions (len(y_train), 1) filled with the mode value\n",
    "y_base=np.full((len(y_train),1),y_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Training: 44268.18510943663\n"
     ]
    }
   ],
   "source": [
    "# Import the function print_class_perf from models.performance and display the ROC-AUC score\n",
    "from src.models.performance import print_mse\n",
    "\n",
    "print_mse(y_train,y_base,set_name='Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5087c292a60e433539a3ea1db33a548e8b6d2b5fd0ec051734d3134be8f1ad1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
